{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D,MaxPooling2D, Flatten, Dense, Dropout, Activation, BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.losses import categorical_crossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-05-16T21:19:08.207612Z","iopub.execute_input":"2023-05-16T21:19:08.208828Z","iopub.status.idle":"2023-05-16T21:19:08.216571Z","shell.execute_reply.started":"2023-05-16T21:19:08.208788Z","shell.execute_reply":"2023-05-16T21:19:08.215301Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt \nfrom sklearn.utils import shuffle","metadata":{"execution":{"iopub.status.busy":"2023-05-16T21:19:08.218913Z","iopub.execute_input":"2023-05-16T21:19:08.219607Z","iopub.status.idle":"2023-05-16T21:19:08.236331Z","shell.execute_reply.started":"2023-05-16T21:19:08.219571Z","shell.execute_reply":"2023-05-16T21:19:08.235448Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Labelilng","metadata":{}},{"cell_type":"code","source":"# PATHS\n# path to the folder containing the subfolders with the training images\ntrainpath = '/kaggle/input/intel-image-classification/seg_train/seg_train'\n# path to the folder containing the subfolders with the testing images\ntestpath = '/kaggle/input/intel-image-classification/seg_test/seg_test'\npredpath = '/kaggle/input/intel-image-classification/seg_pred/seg_pred'","metadata":{"execution":{"iopub.status.busy":"2023-05-16T21:19:08.237673Z","iopub.execute_input":"2023-05-16T21:19:08.238057Z","iopub.status.idle":"2023-05-16T21:19:08.247487Z","shell.execute_reply.started":"2023-05-16T21:19:08.238028Z","shell.execute_reply":"2023-05-16T21:19:08.246463Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Create a dictionary to change text labels into int numerical labels\nclass_names = ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\nclass_labels = {class_name:i for i, class_name in enumerate(class_names)}\n\nprint(class_labels)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T21:19:08.251561Z","iopub.execute_input":"2023-05-16T21:19:08.252638Z","iopub.status.idle":"2023-05-16T21:19:08.258861Z","shell.execute_reply.started":"2023-05-16T21:19:08.252607Z","shell.execute_reply":"2023-05-16T21:19:08.257870Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"{'buildings': 0, 'forest': 1, 'glacier': 2, 'mountain': 3, 'sea': 4, 'street': 5}\n","output_type":"stream"}]},{"cell_type":"code","source":"# def for labeling \n\nimport os\nfrom PIL import Image\nIMAGE_SIZE = (150, 150)\n\ndef labeling(folder_path, images, labels):\n    # loop through all subfolders in the folder_path\n    for label in os.listdir(folder_path):\n        # get the path to the subfolder\n        label_path = os.path.join(folder_path, label)\n\n        # convert label text to label number\n        label_number = class_labels[label]\n\n        # loop through all images in subfolder\n        for file_name in os.listdir(label_path):\n            # upload image using Pillow\n            image = Image.open(os.path.join(label_path, file_name))\n\n            # resize image to desired size\n            image = image.resize(IMAGE_SIZE)\n\n            # convert the image to a Numpy array  \n            image = np.array(image)\n\n            # add image to testing_image list\n            images.append(image)\n\n            # add image label to testing_label list\n            labels.append(label_number)\n    # convert the images and labels list to numpy array\n    images = np.array(images, dtype='float32')\n    labels = np.array(labels, dtype='int32')\n    \n    return images, labels\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-16T21:19:08.260139Z","iopub.execute_input":"2023-05-16T21:19:08.260593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training labeling\n# list to store the images and their labels\ntraining_images = []\ntraining_labels = []\nx_train, y_train = labeling(trainpath, training_images, training_labels)\n\n# Testing labeling\n# list to store the images and their labels\ntesting_images = []\ntesting_labels = []\nx_test, y_test = labeling(testpath, testing_images, testing_labels)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data visualization","metadata":{}},{"cell_type":"code","source":"plt.imshow(training_images[5])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(training_labels[5])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del training_images\ndel training_labels\ndel testing_images\ndel testing_labels\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data prepatation","metadata":{}},{"cell_type":"code","source":"# Find the unique numbers from the train labels\nnum_clases = len(np.unique(y_train))\n\n# Change the labels from categorical to one-hot encoding\ny_train = to_categorical(y_train, num_clases)\ny_test = to_categorical(y_test, num_clases)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize y_train after one hot encoding\ny_train[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Normalization","metadata":{}},{"cell_type":"code","source":"# Using Z-score normalization to converge faster and improve accuracy\nmean = np.mean(x_train)\nstd = np.std(x_train)\n\n\nx_train = (x_train - mean) / (std+1e-7)\nx_test = (x_test - mean) / (std+1e-7)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### validation data","metadata":{}},{"cell_type":"code","source":"# Split train and valid\nx_train, x_valid , y_train, y_valid = train_test_split(x_train, y_train, test_size=0.1, random_state=13)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('train;', x_train.shape[0])\nprint('val;', x_valid.shape[0])\nprint('test;', x_test.shape[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building the convnet model","metadata":{}},{"cell_type":"code","source":"base_filtros = 32\nw_regulatizer = 1e-4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.shape[1:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n## conv 1\nmodel.add(Conv2D(base_filtros, (3,3), padding='same', kernel_regularizer=regularizers.l2(w_regulatizer), input_shape=x_train.shape[1:]))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\n\n## conv 2\nmodel.add(Conv2D(base_filtros, (3,3), padding='same', kernel_regularizer=regularizers.l2(w_regulatizer)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\n## conv 3\nmodel.add(Conv2D(2*base_filtros, (3,3), padding='same', kernel_regularizer=regularizers.l2(w_regulatizer)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\n\n## conv 4\nmodel.add(Conv2D(2*base_filtros, (3,3), padding='same', kernel_regularizer=regularizers.l2(w_regulatizer)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.3))\n\n## conv 5\nmodel.add(Conv2D(4*base_filtros, (3,3), padding='same', kernel_regularizer=regularizers.l2(w_regulatizer)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\n\n\n## conv 6\nmodel.add(Conv2D(4*base_filtros, (3,3), padding='same', kernel_regularizer=regularizers.l2(w_regulatizer)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.4))\n\n## Clasificacion - Flatten\n\nmodel.add(Flatten())\nmodel.add(Dense(30,activation='relu'))\nmodel.add(Dense(num_clases,activation='softmax'))\n\nmodel.summary()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data augmentation","metadata":{}},{"cell_type":"code","source":"datagen = ImageDataGenerator(rotation_range=15,\n                  width_shift_range=0.1,\n                  height_shift_range=0.1,\n                  horizontal_flip=True,\n                  vertical_flip=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Compiling","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import optimizers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(),\n             metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Callbacks","metadata":{}},{"cell_type":"code","source":"chekcpoint = ModelCheckpoint('mejor_modelo_denses1s.hdf5',verbose=1,save_best_only=True, monitor = 'val_accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"hist = model.fit(datagen.flow(x_train, y_train, batch_size=128),\n          callbacks=[chekcpoint],\n          steps_per_epoch=x_train.shape[0] // 128, \n          epochs=50,\n          verbose=1,\n          validation_data=(x_valid, y_valid),\n                 shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Displaying curves of loss and accuracy during training","metadata":{}},{"cell_type":"code","source":"def graph_loss_in_epochs(hist, save_image_filename, title):\n    training_loss = hist.history['loss']\n    test_loss = hist.history['val_loss'] #[10 9 8 5 6 7] 3\n    # Create count of the number of epochs\n    epoch_count = range(1, len(training_loss) + 1) #[1 2 3 4 5 6]\n    # Visualize loss history\n    plt.title(title)\n    plt.plot(epoch_count, training_loss, 'r--')\n    plt.plot(epoch_count, test_loss, 'b-')\n    plt.legend(['Training Loss', 'Test Loss'])\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.axvline(x = epoch_count[test_loss.index(min(test_loss))], color = 'c', linestyle=\"dotted\")\n    plt.savefig('denses1sloss.png')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"graph_loss_in_epochs(hist, 'train_vs_test_loss.png', 'Train vs Test Loss')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining accuracy and loss plot funtion\ndef plot_loss_accuracy(hist, len_epochs):\n  epochs = len_epochs\n  acc = hist.history['accuracy']\n  val_acc = hist.history['val_accuracy']\n\n  loss = hist.history['loss']\n  val_loss = hist.history['val_loss']\n\n  epochs_range = range(epochs)\n\n  plt.figure(figsize=(12, 5))\n  plt.subplot(1, 2, 1)\n  plt.plot(epochs_range, acc, 'r--', label='Training Accuracy')\n  plt.plot(epochs_range, val_acc,'b-' , label='Validation Accuracy')\n  plt.legend(loc='lower right')\n  plt.title('Training and Validation Accuracy')\n\n  plt.subplot(1, 2, 2)\n  plt.plot(epochs_range, loss, 'r--', label='Training Loss')\n  plt.plot(epochs_range, val_loss, 'b-', label='Validation Loss')\n  plt.legend(loc='upper right')\n  plt.title('Training and Validation Loss')\nplt.savefig('denses1sacloss.png')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Call the function to plot the curves\nplot_loss_accuracy(hist, 120)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2 = model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2.load_weights('./mejor_modelo_denses1s.hdf5') ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2.save('shapes_cnnD.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Results","metadata":{}},{"cell_type":"code","source":"model2.evaluate(x_test,y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Inspired by: https://towardsdatascience.com/visualizing-intermediate-activation-in-convolutional-neural-networks-with-keras-260b36d60d0\n\n# Predicting the class of unseen images\nfrom PIL import Image\n\nimg_path = '/kaggle/input/intel-image-classification/seg_pred/seg_pred/10038.jpg'\nimg = Image.open(img_path)\nimg = img.resize((150,150))\nimg_tensor = np.asarray(img)\nimg_tensor = np.expand_dims(img_tensor, axis=0)\nimg_tensor = img_tensor.astype('float32')\nimg_tensor /= 255.\nplt.imshow(img_tensor[0])\nplt.show()\nprint(img_tensor.shape)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predicting images\npredicted_probs = model2.predict(img_tensor)\npredicted_class_idx = np.argmax(predicted_probs)\npredicted_class_label = class_names[predicted_class_idx]\nprint(\"Predicted class is:\", predicted_class_label)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save training metrics","metadata":{}},{"cell_type":"code","source":"import csv\n# Extrae las métricas de rendimiento para cada época desde el objeto de historial:\ntrain_loss = hist.history['loss']\ntrain_acc = hist.history['accuracy']\nval_loss = hist.history['val_loss']\nval_acc = hist.history['val_accuracy']\n\n# Abre el archivo CSV y escribe las métricas de rendimiento:\nwith open('metrics120.csv', 'a') as csvfile:\n    writer = csv.writer(csvfile)\n    writer.writerow(['train_loss', 'train_acc', 'val_loss', 'val_acc'])\n    for i in range(len(train_loss)):\n        writer.writerow([train_loss[i], train_acc[i], val_loss[i], val_acc[i]])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nfrom pickle import dump\nfrom pickle import load\n\ndef save_model(model, file_name):\n    dump(model, open(file_name, 'wb'))\n    \ndef load_model(file_name):\n    return load(file_name, 'rb')\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_name = 'pickle_model_epoch120.pkl'\nsave_model(model, file_name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del x_train\ndel y_train\ndel x_valid\ndel y_valid","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing intermediate activations","metadata":{}},{"cell_type":"code","source":"# Instantiating a model from an input tensor and a list of output tensors\nlayer_outputs = [layer.output for layer in model.layers[:12]] # Extracts the outputs of the top 12 layers\nactivation_model = models.Model(inputs=model.input, outputs=layer_outputs) # Creates a model that will return these outputs, given the model input","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Running the model in predict mode\nactivations = activation_model.predict(img_tensor) # Returns a list of five Numpy arrays: one array per layer activation","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"first_layer_activation = activations[0]\nprint(first_layer_activation.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.matshow(first_layer_activation[0, :, :, 4], cmap='viridis')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualizing every channel in every intermediate activation\nlayer_names = []\nfor layer in model.layers[:12]:\n    layer_names.append(layer.name) # Names of the layers, so you can have them as part of your plot\n    \nimages_per_row = 16\n​\nfor layer_name, layer_activation in zip(layer_names, activations): # Displays the feature maps\n    n_features = layer_activation.shape[-1] # Number of features in the feature map\n    size = layer_activation.shape[1] #The feature map has shape (1, size, size, n_features).\n    n_cols = n_features // images_per_row # Tiles the activation channels in this matrix\n    display_grid = np.zeros((size * n_cols, images_per_row * size))\n    for col in range(n_cols): # Tiles each filter into a big horizontal grid\n        for row in range(images_per_row):\n            channel_image = layer_activation[0,\n                                             :, :,\n                                             col * images_per_row + row]\n            channel_image -= channel_image.mean() # Post-processes the feature to make it visually palatable\n            channel_image /= channel_image.std()\n            channel_image *= 64\n            channel_image += 128\n            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n            display_grid[col * size : (col + 1) * size, # Displays the grid\n                         row * size : (row + 1) * size] = channel_image\n    scale = 1. / size\n    plt.figure(figsize=(scale * display_grid.shape[1],\n                        scale * display_grid.shape[0]))\n    plt.title(layer_name)\n    plt.grid(False)\n    plt.imshow(display_grid, aspect='auto', cmap='viridis')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}